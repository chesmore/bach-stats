{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnpDssuPjhzk",
    "outputId": "7da65f9c-d1d6-4c4f-e4c2-f6ccb46a8239"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "Pj1WgCQcjwRu",
    "outputId": "f3a4ce65-0daf-4f73-d6c9-d43f23db41eb"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('bach_data.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "Edmw4UO_lLeW",
    "outputId": "b66e9495-5c8c-4dad-feed-1cbde8cfa71e"
   },
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "for col in [\"Hometown\", \"Job category\", \"Race\", \"Joke Entrance\"]:\n",
    "  # print( {name:i for i, name in enumerate(data[col].unique())} )\n",
    "  data_clean = data_clean.replace( {name:i for i, name in enumerate(data[col].unique())} )\n",
    "\n",
    "data_clean['FIR'] = np.where( data_clean['FIR?'] == 'Yes' , 1 , 0)\n",
    "\n",
    "data_clean = data_clean.drop(columns=['Name','FIR?', 'Joke Entrance'])\n",
    "\n",
    "new_job_cat = {\n",
    "    'POLITICS':['NEWS', 'MILLITARY', 'POLITICS'],\n",
    "    'CORPORATE':['MARKETING', 'PR', 'RECRUITER', 'ASSISTANT', 'EXECUTIVE', 'SALES', 'FINANCE'],\n",
    "    'TRADES':['RESTAURANT JOB', 'WAITRESS', 'BEAUTY', 'ACTRESS/MODEL', 'DANCER', 'REALTOR', 'EVENT PLANNER', 'FITNESS', 'NANNY'],\n",
    "    'TRADITIONAL':['TEACHER','DENTIST', 'LAWYER', 'MEDICAL', 'SCIENCE/TECHNOLOGY'],\n",
    "    'OTHER':['STUDENTT', 'STUDENT', 'WRITER', 'PASTOR', 'ART', 'NONE', 'JOKE', 'FLIGHT ATTENDANT'],\n",
    "}\n",
    "\n",
    "job_categories = data['Job category'].to_numpy()\n",
    "new_job_categories = []\n",
    "for name in job_categories:\n",
    "  for key, val in new_job_cat.items():\n",
    "    if name in val:\n",
    "      new_name = key\n",
    "  new_job_categories.append( new_name )\n",
    "\n",
    "data_clean['Job category'] = np.array(new_job_categories)\n",
    "\n",
    "\n",
    "new_hometown_cat = {\n",
    "    'INTERNATIONAL':['Canada','International'],\n",
    "    'NE':['Midwestt','East','Midwest','Mid atlantic'],\n",
    "    'NW':['West','Northwest'],\n",
    "    'SE':['South',],\n",
    "    'SW':['Southwest']\n",
    "}\n",
    "home_categories = data['Hometown'].to_numpy()\n",
    "new_home_categories = []\n",
    "for name in home_categories:\n",
    "  for key, val in new_hometown_cat.items():\n",
    "    if name in val:\n",
    "      new_name = key\n",
    "  new_home_categories.append( new_name )\n",
    "\n",
    "data_clean['Hometown'] = np.array(new_home_categories)\n",
    "\n",
    "\n",
    "one_hot_dfs = [data_clean]\n",
    "col_name_one_hot = ['Hometown', 'Race', 'Job category']\n",
    "\n",
    "for name in col_name_one_hot:\n",
    "  num_un = data_clean[name].nunique()\n",
    "  one_hot = pd.get_dummies( data_clean[name] )\n",
    "  one_hot.rename( columns={i:name+f'_{i}' for i in range(num_un)}, inplace=True)\n",
    "  one_hot_dfs.append( one_hot )\n",
    "\n",
    "\n",
    "combined_df = pd.concat( one_hot_dfs, axis=1 )\n",
    "combined_df = combined_df.drop(columns=['Hometown','Job category', 'Race'])\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "3_aXzNLgROns",
    "outputId": "7a11ec15-ad85-4e63-c5a0-14026245cb43"
   },
   "outputs": [],
   "source": [
    "combined_df.Place.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw6Sc9o9jnYy"
   },
   "outputs": [],
   "source": [
    "# combined_df.drop(columns=['Season '], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "3lcZXXFFnvUG",
    "outputId": "18d85254-2a14-43f0-8d46-e6ed2658672c"
   },
   "outputs": [],
   "source": [
    "print( combined_df.Place.value_counts().head() )\n",
    "\n",
    "# Place 16 is over represented in the data set, lets try and reduce this to a 28 (compared to 58)\n",
    "\n",
    "locs_to_remove = np.random.choice(np.where(combined_df.Place == 16)[0], size=37)\n",
    "\n",
    "combined_df.drop(index=locs_to_remove, inplace=True)\n",
    "\n",
    "print( combined_df.Place.value_counts().head() )\n",
    "\n",
    "combined_df.Place.hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "EhS34bzPDxOh",
    "outputId": "dd497761-deb3-49f3-c22d-0544604960dc"
   },
   "outputs": [],
   "source": [
    "# all possible combinations to see which combo is best\n",
    "determine = pd.DataFrame(index=pd.MultiIndex.from_product([combined_df[col].unique() for col in combined_df.columns.drop(['Place', 'Season '])], \n",
    "                                                          names=combined_df.columns.drop(['Place', 'Season ']))).reset_index()\n",
    "\n",
    "determine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJcDnp8y8qoD",
    "outputId": "b4daf8ad-547d-48ec-ed2b-faac07e1d6a0"
   },
   "outputs": [],
   "source": [
    "input_names = list(combined_df.columns)\n",
    "input_names.remove('Place')\n",
    "\n",
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZegWxYDl58I"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "labels = combined_df['Place'].to_numpy()\n",
    "\n",
    "inputs = combined_df[input_names].to_numpy()\n",
    "\n",
    "labels = torch.tensor( labels )\n",
    "inputs = torch.tensor( inputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6pZpjUMugdN",
    "outputId": "9916ec00-2631-418f-e504-3a280d5a1d69"
   },
   "outputs": [],
   "source": [
    "len(np.unique(labels.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n_RP2XlomrZD",
    "outputId": "9186eaf6-1012-4bcf-aaba-e62fd552b6b0"
   },
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "\n",
    "      # this defines the model\n",
    "        def __init__(self, input_size, hidden_size, n_hidden_layers):\n",
    "            super(MLP, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.n_hidden_layers = n_hidden_layers\n",
    "\n",
    "            self.hiddenlayer = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "            \n",
    "            for i in range(self.n_hidden_layers):\n",
    "                setattr( self, f'mid_layer_{i}', torch.nn.Linear(self.hidden_size, self.hidden_size) )\n",
    "            \n",
    "            # self.hiddenlayer_mid = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "\n",
    "            self.outputlayer = torch.nn.Linear(self.hidden_size, 25) # number of classes, Places\n",
    "\n",
    "            # Normalizations\n",
    "            # self.batch_norm_layer_input = torch.nn.BatchNorm1d(self.input_size) \n",
    "            self.batch_norm_layer = torch.nn.BatchNorm1d(self.hidden_size)\n",
    "\n",
    "            # some nonlinear options\n",
    "            self.sigmoid = torch.nn.Sigmoid() # binary\n",
    "            self.softmax = torch.nn.Softmax()\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.leaky_relu = torch.nn.LeakyReLU(0.01)\n",
    "\n",
    "        def forward(self, x):\n",
    "            layer1 = self.hiddenlayer(x)\n",
    "            activation = self.leaky_relu(layer1)\n",
    "\n",
    "            for i in range(self.n_hidden_layers):\n",
    "                _hiddenlayer = getattr(self, f'mid_layer_{i}')\n",
    "                layer = _hiddenlayer(activation)\n",
    "                activation = self.leaky_relu( self.batch_norm_layer(layer) )\n",
    "\n",
    "            # layer2 = self.hiddenlayer_mid(activation)\n",
    "            # activation = self.leaky_relu( self.batch_norm_layer(layer2) )\n",
    "\n",
    "            layer3 = self.outputlayer(activation)\n",
    "            output = self.softmax( layer3 )\n",
    "            return output\n",
    "\n",
    "MLP(10, 20, 1) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "dA1OE3YasRhx",
    "outputId": "01401749-fa45-4473-f1c3-ac7de2f6537c"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# train the model\n",
    "def train_model(training_data, training_labels, test_data,test_labels, model):\n",
    "  # define the optimization\n",
    "  # criterion = torch.nn.MSELoss() # output layer size = 1\n",
    "  # criterion = torch.nn.BCELoss() # output layer size = 25\n",
    "  criterion = torch.nn.CrossEntropyLoss() # weighted costs \n",
    "\n",
    "  # def mean_power_err_loss(input, target, power=3):\n",
    "  #   return torch.mean(torch.abs(input - target) ** power)\n",
    "  # criterion = mean_power_err_loss\n",
    "\n",
    "  # optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "\n",
    "  optimizer = torch.optim.Adam( model.parameters(), lr=1e-3, betas=(0.9, 0.999) )\n",
    "  # Increase the number of epochs for your \"final\" run\n",
    "  epochs, losses = [], []\n",
    "  for epoch in tqdm(range(70_000)):\n",
    "\n",
    "    # clear the gradient\n",
    "    optimizer.zero_grad()\n",
    "    # compute the model output\n",
    "    myoutput = model(training_data.float())\n",
    "\n",
    "    # calculate loss\n",
    "    loss = criterion(myoutput, training_labels.float())\n",
    "\n",
    "    # credit assignment\n",
    "    loss.backward()\n",
    "    # update model weights\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%200 == 0:\n",
    "      epochs.append(epoch)\n",
    "      losses.append(loss.detach().numpy())\n",
    "\n",
    "  # ADD PLOT\n",
    "  fig, ax = plt.subplots(1,1, dpi=120)\n",
    "  ax.scatter(epochs, losses)\n",
    "  ax.set_ylabel('loss')\n",
    "  ax.set_xlabel('epoch')\n",
    "  print(losses[-1])\n",
    "  return fig, ax, model\n",
    "\n",
    "\n",
    "# convert ranks or contestants into probability array \n",
    "p_labels = torch.zeros( (len(labels),25), dtype=torch.long)\n",
    "for i, rank in enumerate(labels):\n",
    "  p_labels[i,rank-1] = 1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, \n",
    "                                                    p_labels, \n",
    "                                                    # np.reshape(labels, (len(labels),1)), \n",
    "                                                    test_size=0.33, train_size=0.67, random_state=12345 )\n",
    "\n",
    "num_feat = X_train.numpy().shape[1]\n",
    "model = MLP( input_size=num_feat, hidden_size=num_feat, n_hidden_layers=1 )\n",
    "print(model)\n",
    "fig, ax, model = train_model( X_train, y_train, X_test, y_test, model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "elkBSz00tVBv",
    "outputId": "c14332be-6551-4a24-a2b9-1ab04bd33b22"
   },
   "outputs": [],
   "source": [
    "pred = model( X_test.float() ).detach().numpy()\n",
    "\n",
    "# plt.scatter( y_train, np.argmax(pred, axis=1) )\n",
    "# plt.scatter( np.argmax(y_test, axis=1), np.argmax(pred, axis=1) )\n",
    "# plt.show()\n",
    "\n",
    "fig, subs = plt.subplots(nrows=1,ncols=2, figsize=(6,3), gridspec_kw={'width_ratios': [1,2]},dpi=150)\n",
    "subs[0].imshow( pred, aspect='equal', extent=(0,25, 0,50), cmap='RdPu')\n",
    "\n",
    "ind=0\n",
    "\n",
    "dat = subs[1].scatter( np.argmax(pred, axis=1), np.argmax(y_test, axis=1), c=X_test.numpy()[:,ind], label=input_names[ind] )\n",
    "subs[1].plot( np.arange(0,25), np.arange(0,25), '-k', zorder=0 )\n",
    "subs[1].grid(alpha=0.25)\n",
    "fig.colorbar(dat, label=input_names[ind])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "score = balanced_accuracy_score( np.argmax(y_test, axis=1),  np.argmax(pred, axis=1) )\n",
    "print( score, 1/25 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qu24_mOFsSVt",
    "outputId": "4e71c355-3b57-4cb9-82c3-fff008c4f0c4"
   },
   "outputs": [],
   "source": [
    "[f\"{i},{val}\" for i, val in enumerate(input_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ooX4BfbnuNp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "# arr = np.linspace(0, 50, 100).reshape((10, 10))\n",
    "# fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "# cmap = plt.get_cmap('jet')\n",
    "# new_cmap = truncate_colormap(cmap, 0.2, 0.8)\n",
    "# ax[0].imshow(arr, interpolation='nearest', cmap=cmap)\n",
    "# ax[1].imshow(arr, interpolation='nearest', cmap=new_cmap)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HABAR7-0I16Y"
   },
   "outputs": [],
   "source": [
    "# install latex for matplotlib\n",
    "!sudo apt install cm-super dvipng texlive-latex-extra texlive-latex-recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "z35Ux_iytVZY",
    "outputId": "69bea827-682a-461b-9bd2-bed631745ff6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('drive/MyDrive/DSFP_data/mpl_style.txt')\n",
    "\n",
    "\n",
    "cm = confusion_matrix( np.argmax(y_test, axis=1),  np.argmax(pred, axis=1) )\n",
    "\n",
    "disp = ConfusionMatrixDisplay( confusion_matrix=cm, display_labels=[i for i in range(1,26)] )\n",
    "\n",
    "fig, ax = plt.subplots( 1, 1, figsize=(7,7), dpi=150)\n",
    "\n",
    "cmap = plt.get_cmap('RdPu')\n",
    "custom_cmap = truncate_colormap(cmap, 0.0, 0.8)\n",
    "\n",
    "disp.plot(ax = ax, cmap=custom_cmap, colorbar=False)\n",
    "\n",
    "plt.colorbar( mappable=disp.im_, ax=ax, fraction=0.046, pad=0.04 )\n",
    "\n",
    "for i in range(25):\n",
    "  rect = patches.Rectangle( (i-.5, i-.5), 1, 1, linewidth=1, edgecolor='k', facecolor='none')\n",
    "  # Add the patch to the Axes\n",
    "  ax.add_patch(rect)\n",
    "\n",
    "ax.set_xlabel( 'Predicted Place', fontsize=12,)\n",
    "ax.set_ylabel( 'True Place', fontsize=12,)\n",
    "\n",
    "# plt.savefig('drive/MyDrive/DSFP_data/NN_conf_matr.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFkoa2wC0Tjz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A73IHXsUXEPX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9FQCTaiLfdp",
    "outputId": "76a5ca11-f702-44e9-b4eb-cfbb090f98cf"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e-gyCQcL0vB",
    "outputId": "2e5b0a6d-4149-4d9e-bb9a-a1c5a8b088c5"
   },
   "outputs": [],
   "source": [
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "print(input, '\\n', target)\n",
    "\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "\n",
    "output = loss(input, target)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgQc65FxdWIT",
    "outputId": "d3f5b584-e55a-4562-9c24-4f97a6dfb7e8"
   },
   "outputs": [],
   "source": [
    "np.unique( X_train[:,1].numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7gpYiNS2eJNe",
    "outputId": "0fd35cd5-2a7c-4b56-b5d7-94502e410aa3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score( np.random.randint(low=1, high=25, size=600_000),  np.random.randint(low=1, high=25, size=600_000) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogYdVzx2eXfX",
    "outputId": "f0cbd6de-9aa1-4925-8cbf-5e806c9a4443"
   },
   "outputs": [],
   "source": [
    "1/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "id": "gZfYl8gpVtAG",
    "outputId": "ece1b6d5-5939-410a-baa7-12309196d6f5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,2))\n",
    "plt.hist( combined_df.Place, bins=25, histtype='step', color='pink', linewidth=2 )\n",
    "plt.grid(alpha=0.1)\n",
    "plt.xticks( np.arange(1,26,2) )\n",
    "plt.xlabel('Place')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# plt.savefig('drive/MyDrive/DSFP_data/NN_places_hist.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "4LSV5fewaDtP",
    "outputId": "1d9fd222-17da-4895-f2a7-4bb1e9e8eb75"
   },
   "outputs": [],
   "source": [
    "\n",
    "pred = model( X_test.float() ).detach().numpy()\n",
    "\n",
    "fig, subs = plt.subplots(nrows=1,ncols=2, figsize=(3,3),dpi=250)\n",
    "\n",
    "locs = np.argsort( np.argmax(y_test.numpy(), axis=1) )\n",
    "\n",
    "subs[0].imshow( pred[locs,:] , cmap='RdPu', extent=(0,25, 0,130) )\n",
    "subs[1].imshow( y_test.numpy()[locs,:],  cmap='bone', extent=(0,25, 0,130) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwBJlkMexVgz",
    "outputId": "39b695a3-ec8b-46e9-8391-bedd6abeac6b"
   },
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hIa2q3nnxZIa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bachelor_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
